{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "discovery-frequent-itemsets-association-rules.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiordXAFEPtb"
      },
      "source": [
        "# Discovery of Frequent Itemsets and Association Rules\n",
        "This notebook aims to implement the Apriori algorithm to discover association rules between itemsets in a sales transaction database (i.e. a set of baskets). The task includes the following two sub-problems [[R. Agrawal and R. Srikant, VLDB '94](http://www.vldb.org/conf/1994/P487.PDF)]:\n",
        "\n",
        "1. Finding frequent itemsets with support at least s. That means these item sets must appear together in a number of baskets greater than *s * total_baskets*.\n",
        "2. Generating association rules with confidence at least c from the itemsets found in the first step.\n",
        "\n",
        "## Implementation\n",
        "This project has been developed using only NumPy and the native dictionary implementation for Python. We decided not to use PySpark because the transaction file fits in memory and, due to the lack of a distributed cluster, the speed will be equivalent. Also the implementation is extremely fast as we decided not only store singletons but also the list of the baskets the element appears in into a dictionary so the access time is O(1).\n",
        "\n",
        "The execution time for the implemented Apriori algorithm, with the given database, was around 13.5 seconds. The implemented Association Rules algorithm took around 8,27 ms to complete. \n",
        "\n",
        "Some additional libraries to highlight were urllib.request, to download the transaction file from remote storage, pandas, to visualize the resulting table, and run experiments comparing it with the python dictionary, and finally functools and itertools for helper functions for combinations and reduction of lists.\n",
        "\n",
        "## Authors\n",
        "- Serghei Socolovschi [serghei@kth.se](mailto:serghei@kth.se)\n",
        "- Angel Igareta [alih2@kth.se](mailto:alih2@kth.se)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5kXpOJOEgVA"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyin_KVZFl92"
      },
      "source": [
        "import urllib.request\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import permutations, combinations\n",
        "from functools import reduce"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOlPZQccEnjD"
      },
      "source": [
        "## Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOEHsd7kOWqq"
      },
      "source": [
        "### Extract singletons\n",
        "Stores the singletons (unique elements among all baskets) together with the list of the baskets the element appears in into a dictionary so the access time is O(1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5TM0yWFD4uA"
      },
      "source": [
        "def extract_singletons(dataset):\n",
        "  singletons = {}\n",
        "\n",
        "  for basket_index in range(len(dataset)):\n",
        "    item_set = dataset[basket_index]\n",
        "    for item in item_set:\n",
        "      key = str(item)\n",
        "      if key not in singletons.keys():\n",
        "        singletons[key] = np.array([basket_index])\n",
        "      else:\n",
        "        singletons[key] = np.append(singletons[key], basket_index)\n",
        "\n",
        "  return singletons"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T4wyvP2RGTT"
      },
      "source": [
        "### Generate combinations\n",
        "Generates combinations of the current item set and the singletons. For each singleton and frequent itemset, it generates a new item set and in the end, checks that all of them are unique (without taking into account the order).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_01UlFgl9oIb"
      },
      "source": [
        "separator = \"-\" # When the new combined key is composed of multiple items, they are aggregated in a string and separated by a '-'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm-8Sk20erAa"
      },
      "source": [
        "def generate_combinations(frequent_item_sets, size):\n",
        "  combinations = set()\n",
        "\n",
        "  for i in range(len(frequent_item_sets)):\n",
        "    for j in range(i, len(frequent_item_sets)):\n",
        "      potential_combination = sorted(set(frequent_item_sets[i].split(separator) + frequent_item_sets[j].split(separator)))\n",
        "      if len(potential_combination) == size:\n",
        "        combinations.add(separator.join(potential_combination))\n",
        "\n",
        "  return combinations"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsnMKg8nfSjn",
        "outputId": "d3e6a66e-a4db-4e6b-fcb7-03c59edd7721"
      },
      "source": [
        "generate_combinations(['2-3', '3-2', '2-4', '6-5'], 3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'2-3-4'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsjdnV1Xfizo",
        "outputId": "80f424a0-4ee4-437e-8935-4c3519c678ba"
      },
      "source": [
        "generate_combinations(['2-3-4', '3-4-5', '5-7-8'], 4)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'2-3-4-5'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqXnsWLI9L85",
        "outputId": "6fc8dd9b-e80c-479c-c917-0a1d108c53c9"
      },
      "source": [
        "set(combinations([1, 2, 3], 2))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(1, 2), (1, 3), (2, 3)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DYDMQlC5pph"
      },
      "source": [
        "### Search frequent item sets\n",
        "Recursive approach for finding frequent itemsets. First, it calculates the combinations of size k (k starting from 2) and, for each combination, it calculates the similarity of the items. If this similarity (number of baskets where these items appear together) is over the baskets threshold, the item is stored in an array that will be returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJQ9KYvyEkvF"
      },
      "source": [
        "def search_frequent_itemsets(previous_item_sets, singletons, selected_item_sets, baskets_threshold, k = 2):\n",
        "  # New candidates of size k are computed by adding to the previous item sets the singletons.\n",
        "  combinations_size_k = generate_combinations(list(previous_item_sets.keys()), k)\n",
        "\n",
        "  # If no more combinations can be generated with the previous item sets, return selected.\n",
        "  if len(combinations_size_k) == 0:\n",
        "    return selected_item_sets\n",
        "  # Otherwise, append item sets that are over the similarity threshold.\n",
        "  else:\n",
        "    current_item_sets = {}\n",
        "    for combination in combinations_size_k:      \n",
        "      combination_array = combination.split(separator)\n",
        "      are_subsets_frequent = False\n",
        "      if k == 2:\n",
        "        # No need to check as previous items were already pruned\n",
        "        are_subsets_frequent = True\n",
        "      else: \n",
        "        # First, check all subset k - 1 of current combination is is in previous item sets\n",
        "        combination_subsets = [separator.join(combination) for combination in combinations(combination_array, k - 1)]\n",
        "        subset_intersection = np.intersect1d(combination_subsets, list(previous_item_sets.keys()))\n",
        "        are_subsets_frequent = len(subset_intersection) == len(combination_subsets)\n",
        "\n",
        "      # If all the subsets are frequent\n",
        "      if are_subsets_frequent:\n",
        "        # For each item, get baskets set and intersect all of them.\n",
        "        tuple_total_baskets = [singletons[combination] for combination in combination_array]\n",
        "        tuple_total_baskets_intersection = reduce(np.intersect1d, (tuple_total_baskets))\n",
        "\n",
        "        # If the intersection is over the similarity_threshold, add it to the current item sets.\n",
        "        if (len(tuple_total_baskets_intersection) > baskets_threshold):\n",
        "          current_item_sets[combination] = tuple_total_baskets_intersection\n",
        "    \n",
        "    return search_frequent_itemsets(current_item_sets, singletons, dict(selected_item_sets, **current_item_sets), baskets_threshold, k + 1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY45midFcW8l"
      },
      "source": [
        "### Generate permutations for rules\n",
        "For each possible subarray of item_set with size k, find all possible combinations and add k items at the left part and the other n - k at the right part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LblkPyea4BAS"
      },
      "source": [
        "def generate_rules(item_set):\n",
        "  candidates = []\n",
        "  for k in range(1, len(item_set)):\n",
        "    for combination in list(combinations(item_set, k)):\n",
        "      left_part = list(combination)\n",
        "      right_part = [item for item in item_set if item not in left_part]\n",
        "      candidates.append((left_part, right_part))\n",
        "  \n",
        "  return candidates"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXL2OfUGcsDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7616dc5b-91e9-459c-b6b8-994442c7f39c"
      },
      "source": [
        "example_list = ['390', '722', '222', '444']\n",
        "\n",
        "for i in range(0, len(example_list) - 1):\n",
        "  example_sublist = example_list[:len(example_list) - i]\n",
        "  print(\"\\nRules generated for list: \" + str(example_sublist))\n",
        "  for candidate in generate_rules(example_sublist):\n",
        "    print(str(candidate[0]) + \" => \" + str(candidate[1]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Rules generated for list: ['390', '722', '222', '444']\n",
            "['390'] => ['722', '222', '444']\n",
            "['722'] => ['390', '222', '444']\n",
            "['222'] => ['390', '722', '444']\n",
            "['444'] => ['390', '722', '222']\n",
            "['390', '722'] => ['222', '444']\n",
            "['390', '222'] => ['722', '444']\n",
            "['390', '444'] => ['722', '222']\n",
            "['722', '222'] => ['390', '444']\n",
            "['722', '444'] => ['390', '222']\n",
            "['222', '444'] => ['390', '722']\n",
            "['390', '722', '222'] => ['444']\n",
            "['390', '722', '444'] => ['222']\n",
            "['390', '222', '444'] => ['722']\n",
            "['722', '222', '444'] => ['390']\n",
            "\n",
            "Rules generated for list: ['390', '722', '222']\n",
            "['390'] => ['722', '222']\n",
            "['722'] => ['390', '222']\n",
            "['222'] => ['390', '722']\n",
            "['390', '722'] => ['222']\n",
            "['390', '222'] => ['722']\n",
            "['722', '222'] => ['390']\n",
            "\n",
            "Rules generated for list: ['390', '722']\n",
            "['390'] => ['722']\n",
            "['722'] => ['390']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQsXti2eVR9A"
      },
      "source": [
        "### Generate association rules\n",
        "For each selected item set (frequent itemsets excluding singletons), generate each of the possible rules between the items within the set and return the ones in which confidence is higher than the threshold.\n",
        "- Confidence: conf(I => j) = support(I ⋃ j) / support(I)\n",
        "- Interest: Confidence - Pr[j]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmPCc0Sf58yj"
      },
      "source": [
        "def generate_association_rules(selected_item_sets, frequent_item_sets, total_baskets, confidence_threshold = 0.5):\n",
        "  selected_rules = []\n",
        "  # Iterates over the groups of frequent items and generating candidates for association rules from them.\n",
        "  for item_set_raw in selected_item_sets:\n",
        "    item_set = item_set_raw.split(separator) # From {'A-B-C'} -> ['A', 'B', 'C']\n",
        "    candidate_rules = generate_rules(item_set)\n",
        "\n",
        "    # Extracting lists of baskets from left part and right part of candidate association rule.\n",
        "    for left_part, right_part in candidate_rules:\n",
        "      left_part_baskets = frequent_item_sets[separator.join(left_part)]\n",
        "      right_part_baskets = frequent_item_sets[separator.join(right_part)]\n",
        "\n",
        "      # Calculate confidence and interest.\n",
        "      confidence = len(np.intersect1d(left_part_baskets, right_part_baskets)) / len(left_part_baskets)\n",
        "      interest = confidence - (len(right_part_baskets) / total_baskets)\n",
        "\n",
        "      if confidence > confidence_threshold:\n",
        "        rule = \"{\" + \", \".join(left_part) + \"} => {\" + \", \".join(right_part) + \"}\"\n",
        "        selected_rules.append((rule, confidence, interest))\n",
        "          \n",
        "  return selected_rules"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apcuANP1EjdG"
      },
      "source": [
        "## Main method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfqQSUcjEs71"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9UQk7viRCN6"
      },
      "source": [
        "similarity_threshold = 0.01\n",
        "confidence_threshold = 0.5"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KJbSacMEh5Y"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ28aPAdFUDB"
      },
      "source": [
        "dataset_url = \"https://drive.google.com/uc?export=download&id=1xDIIHRMZcnOcUDvp0R48z-YEiDhrZ9FT\" # Add here path to T10I4D100K.dat\n",
        "dataset_raw = urllib.request.urlopen(dataset_url)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy_xFJegIn4A"
      },
      "source": [
        "def transform_item_function(item_set_string):\n",
        "  item_set_raw = item_set_string.strip().split() # Split items in item set\n",
        "  item_set = [int(item_raw) for item_raw in item_set_raw] # Convert items to int\n",
        "  return np.array(item_set)\n",
        "\n",
        "dataset = [transform_item_function(item_set_string) for item_set_string in dataset_raw]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7ZxbgX6FhfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d98ed5f-c43d-4220-cb06-5eaff3f27439"
      },
      "source": [
        "dataset[:2]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 25,  52, 164, 240, 274, 328, 368, 448, 538, 561, 630, 687, 730,\n",
              "        775, 825, 834]),\n",
              " array([ 39, 120, 124, 205, 401, 581, 704, 814, 825, 834])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhHPWmkQQLuS"
      },
      "source": [
        "### Frequent Itemsets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOZmMynHX1vg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e7bc4c0-954b-45e6-91b4-fed2a523be67"
      },
      "source": [
        "total_baskets = len(dataset)\n",
        "baskets_threshold = similarity_threshold * total_baskets\n",
        "print(\"Total baskets: \" + str(total_baskets))\n",
        "print(\"Baskets threshold: \" + str(baskets_threshold))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total baskets: 100000\n",
            "Baskets threshold: 1000.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0nqNcTkQQKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f29967c9-f02f-4a7f-f531-5dcb6cf0bbdd"
      },
      "source": [
        "# Extract singletons from dataset\n",
        "singletons = extract_singletons(dataset)\n",
        "print(\"Total items: \" + str(len(singletons.keys())))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total items: 870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aKjLaDDXxFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ddd5bb-6ac5-44ce-bfa0-1d73d7e3b65c"
      },
      "source": [
        "# Filter singletons\n",
        "new_singletons = {}\n",
        "\n",
        "for (key, value) in singletons.items():\n",
        "  if len(value) > baskets_threshold:\n",
        "    new_singletons[key] = value\n",
        "\n",
        "singletons = new_singletons\n",
        "print(\"Items over similarity threshold: \" + str(len(singletons.keys())))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Items over similarity threshold: 375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIM8e00aEhU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eddcd97-3930-4993-c55e-669ef7f1d498"
      },
      "source": [
        "%%timeit\n",
        "search_frequent_itemsets(singletons, singletons, [], baskets_threshold)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 13.3 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSRFM46LGrbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a1406a-da56-4c32-f63a-c3d3aa6c5337"
      },
      "source": [
        "%%time\n",
        "selected_item_sets = search_frequent_itemsets(singletons, singletons, [], baskets_threshold)\n",
        "print(selected_item_sets.keys())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['227-390', '217-346', '39-825', '368-682', '390-722', '39-704', '704-825', '789-829', '368-829', '39-704-825'])\n",
            "CPU times: user 13.5 s, sys: 4.96 ms, total: 13.5 s\n",
            "Wall time: 13.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGV7F9dNVOHb"
      },
      "source": [
        "### Association rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hSmmsCbAQgp"
      },
      "source": [
        "frequent_item_sets = dict(singletons, **selected_item_sets)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KuFLTwy8ZAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2014006-6bba-4885-c1fb-90b5567ddc1e"
      },
      "source": [
        "%%timeit # 8.39 ms per loop\n",
        "generate_association_rules(selected_item_sets, frequent_item_sets, total_baskets, confidence_threshold)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 8.27 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPWOT-2OVZwV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "3302ef51-5287-4823-f7eb-3382b1525d97"
      },
      "source": [
        "%time\n",
        "association_rules = generate_association_rules(selected_item_sets, frequent_item_sets, total_baskets, confidence_threshold)\n",
        "df = pd.DataFrame(association_rules, columns =['Rule', 'Confidence', 'Interest'])\n",
        "df.head(20)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.91 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rule</th>\n",
              "      <th>Confidence</th>\n",
              "      <th>Interest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{227} =&gt; {390}</td>\n",
              "      <td>0.577008</td>\n",
              "      <td>0.550158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{704} =&gt; {39}</td>\n",
              "      <td>0.617057</td>\n",
              "      <td>0.574477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{704} =&gt; {825}</td>\n",
              "      <td>0.614270</td>\n",
              "      <td>0.583420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{704} =&gt; {39, 825}</td>\n",
              "      <td>0.576923</td>\n",
              "      <td>0.565053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{39, 704} =&gt; {825}</td>\n",
              "      <td>0.934959</td>\n",
              "      <td>0.904109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{39, 825} =&gt; {704}</td>\n",
              "      <td>0.871946</td>\n",
              "      <td>0.854006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{704, 825} =&gt; {39}</td>\n",
              "      <td>0.939201</td>\n",
              "      <td>0.896621</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Rule  Confidence  Interest\n",
              "0      {227} => {390}    0.577008  0.550158\n",
              "1       {704} => {39}    0.617057  0.574477\n",
              "2      {704} => {825}    0.614270  0.583420\n",
              "3  {704} => {39, 825}    0.576923  0.565053\n",
              "4  {39, 704} => {825}    0.934959  0.904109\n",
              "5  {39, 825} => {704}    0.871946  0.854006\n",
              "6  {704, 825} => {39}    0.939201  0.896621"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH0rXsrBNgap"
      },
      "source": [
        "## Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxvaOq5QM3dq"
      },
      "source": [
        "### Pandas version\n",
        "Alternative implementation of the search for frequent itemsets where instead of a python dictionary, the library pandas is used. However, the running time of the experiment turned out to be 62 seconds (average from 3 loops), which is 4 times slower than the native implementation, so it was discarded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haGn6o95aLP_"
      },
      "source": [
        "def generate_combinations_pd(frequent_item_sets, singletons, size):\r\n",
        "  combinations = set()\r\n",
        "\r\n",
        "  for singleton in singletons:\r\n",
        "    for item in frequent_item_sets:\r\n",
        "      potential_combination = sorted(set([singleton] + item.split(separator)))\r\n",
        "      if len(potential_combination) == size:\r\n",
        "        combinations.add(separator.join(potential_combination))\r\n",
        "\r\n",
        "  return combinations"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb-VZxABnEWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44af1e27-85cf-46eb-d8d2-6cf10fe3fa68"
      },
      "source": [
        "generate_combinations_pd(['2-3', '3-2'], ['2', '6'], 3)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'2-3-6'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQgLRFpjNpoq"
      },
      "source": [
        "def extract_singletons_pd(dataset):\n",
        "  singletons_dic = {}\n",
        "  for basket_index in range(len(dataset)):\n",
        "    item_set = dataset[basket_index]\n",
        "    for item in item_set:\n",
        "      key = str(item) # This key will be separated by - when representing more than 1 item\n",
        "      if key not in singletons_dic.keys():\n",
        "        singletons_dic[key] = (1, np.array([basket_index]))\n",
        "      else:\n",
        "        singletons_dic[key] = (singletons_dic[key][0] + 1,  np.append(singletons_dic[key][1], basket_index))\n",
        "\n",
        "  singletons = pd.DataFrame(list(singletons_dic.items()), columns = [\"key\", \"tuple\"]).set_index('key')\n",
        "\n",
        "  # Split tuple into count and baskets\n",
        "  return pd.DataFrame(singletons['tuple'].tolist(), columns = ['count', 'baskets'], index=singletons.index)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUVKTkccNy-f"
      },
      "source": [
        "def search_frequent_itemsets_pd(previous_item_sets, singletons, selected_item_sets, baskets_threshold, k = 2):\n",
        "  combinations_size_k = generate_combinations_pd(previous_item_sets, singletons.index.values, k)\n",
        "\n",
        "  # If no more generations can be generated with the previous item sets, return selected\n",
        "  if len(combinations_size_k) == 0:\n",
        "    return selected_item_sets\n",
        "  # Otherwise, append item sets over the similarity threshold\n",
        "  else:\n",
        "    current_item_sets = []\n",
        "    for combination in combinations_size_k:\n",
        "      # For each item, get baskets set and intersect it\n",
        "      tuple_total_baskets = singletons.loc[combination.split(separator), \"baskets\"].to_numpy()\n",
        "      tuple_total_baskets_intersection = reduce(np.intersect1d, (tuple_total_baskets))\n",
        "\n",
        "      # If the intersection is over the similarity_threshold add it to the pandas dataframe\n",
        "      if (len(tuple_total_baskets_intersection) > baskets_threshold):\n",
        "        current_item_sets.append(combination)\n",
        "    \n",
        "    return search_frequent_itemsets_pd(current_item_sets, singletons, selected_item_sets + current_item_sets, baskets_threshold, k + 1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nogkqna9M7r2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae9fc397-0064-4075-8067-8c19eb25b564"
      },
      "source": [
        "%%timeit # 1 min 2s per loop\n",
        "singletons_pd = extract_singletons_pd(dataset)\n",
        "singletons_pd = singletons_pd[singletons_pd['count'] > baskets_threshold]\n",
        "selected_item_sets = search_frequent_itemsets_pd(singletons_pd.index.values, singletons_pd, [], baskets_threshold)\n",
        "print(selected_item_sets)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['227-390', '217-346', '39-825', '368-682', '390-722', '39-704', '704-825', '789-829', '368-829', '39-704-825']\n",
            "['227-390', '217-346', '39-825', '368-682', '390-722', '39-704', '704-825', '789-829', '368-829', '39-704-825']\n",
            "['227-390', '217-346', '39-825', '368-682', '390-722', '39-704', '704-825', '789-829', '368-829', '39-704-825']\n",
            "['227-390', '217-346', '39-825', '368-682', '390-722', '39-704', '704-825', '789-829', '368-829', '39-704-825']\n",
            "1 loop, best of 3: 1min 1s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}